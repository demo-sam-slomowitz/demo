{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32abf732-7d20-42cc-ae15-3a174c81722e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting splinter\n",
      "  Downloading splinter-0.21.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: urllib3<3.0,>=1.26.14 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from splinter) (2.3.0)\n",
      "Downloading splinter-0.21.0-py3-none-any.whl (40 kB)\n",
      "Installing collected packages: splinter\n",
      "Successfully installed splinter-0.21.0\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.34.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting urllib3~=2.5.0 (from urllib3[socks]~=2.5.0->selenium)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting trio~=0.30.0 (from selenium)\n",
      "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.12.2 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting certifi>=2025.6.15 (from selenium)\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting typing_extensions~=4.14.0 (from selenium)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (3.7)\n",
      "Collecting outcome (from trio~=0.30.0->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.17.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
      "Downloading selenium-4.34.2-py3-none-any.whl (9.4 MB)\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 3.7/9.4 MB 21.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.4 MB 24.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.4/9.4 MB 22.2 MB/s eta 0:00:00\n",
      "Downloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: wsproto, urllib3, typing_extensions, outcome, certifi, trio, trio-websocket, selenium\n",
      "\n",
      "  Attempting uninstall: urllib3\n",
      "\n",
      "   ----- ---------------------------------- 1/8 [urllib3]\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "   ----- ---------------------------------- 1/8 [urllib3]\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "   ----- ---------------------------------- 1/8 [urllib3]\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "   ----- ---------------------------------- 1/8 [urllib3]\n",
      "   ----- ---------------------------------- 1/8 [urllib3]\n",
      "   ----- ---------------------------------- 1/8 [urllib3]\n",
      "   ----- ---------------------------------- 1/8 [urllib3]\n",
      "  Attempting uninstall: typing_extensions\n",
      "   ----- ---------------------------------- 1/8 [urllib3]\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "   ----- ---------------------------------- 1/8 [urllib3]\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "   ----- ---------------------------------- 1/8 [urllib3]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "  Attempting uninstall: certifi\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "    Found existing installation: certifi 2025.4.26\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "    Uninstalling certifi-2025.4.26:\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "      Successfully uninstalled certifi-2025.4.26\n",
      "   ---------- ----------------------------- 2/8 [typing_extensions]\n",
      "   -------------------- ------------------- 4/8 [certifi]\n",
      "   ------------------------- -------------- 5/8 [trio]\n",
      "   ------------------------- -------------- 5/8 [trio]\n",
      "   ------------------------- -------------- 5/8 [trio]\n",
      "   ------------------------- -------------- 5/8 [trio]\n",
      "   ------------------------- -------------- 5/8 [trio]\n",
      "   ------------------------- -------------- 5/8 [trio]\n",
      "   ------------------------- -------------- 5/8 [trio]\n",
      "   ------------------------- -------------- 5/8 [trio]\n",
      "   ------------------------- -------------- 5/8 [trio]\n",
      "   ------------------------- -------------- 5/8 [trio]\n",
      "   ------------------------- -------------- 5/8 [trio]\n",
      "   ------------------------- -------------- 5/8 [trio]\n",
      "   ------------------------------ --------- 6/8 [trio-websocket]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ----------------------------------- ---- 7/8 [selenium]\n",
      "   ---------------------------------------- 8/8 [selenium]\n",
      "\n",
      "Successfully installed certifi-2025.7.14 outcome-1.3.0.post0 selenium-4.34.2 trio-0.30.0 trio-websocket-0.12.2 typing_extensions-4.14.1 urllib3-2.5.0 wsproto-1.2.0\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install splinter\n",
    "!pip install selenium\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "963baf7f-3ebc-48ea-8132-32207b2a55e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from webdriver-manager) (1.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2025.7.14)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: webdriver-manager\n",
      "Successfully installed webdriver-manager-4.0.2\n",
      "Requirement already satisfied: pandas in c:\\users\\samsl\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\samsl\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc4f4b9-fc01-45d0-a63e-cdb531939922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'Mayo Clinic - Rochester', 'United States', 'Rochester', 'MN']\n",
      "['2', 'Cleveland Clinic', 'United States', 'Cleveland', 'OH']\n",
      "['3', 'Massachusetts General Hospital', 'United States', 'Boston', 'MA']\n",
      "['4', 'The Johns Hopkins Hospital', 'United States', 'Baltimore', 'MD']\n",
      "['5', 'Toronto General - University Health Network', 'Canada', 'Toronto', '']\n",
      "['6', 'Karolinska Universitetssjukhuset', 'Sweden', 'Solna', '']\n",
      "['7', 'Charit? - Universit?tsmedizin Berlin', 'Germany', 'Berlin', '']\n",
      "['8', 'AP-HP - H?pital Universitaire Piti? Salp?tri?re', 'France', 'Paris', '']\n",
      "['9', 'Singapore General Hospital', 'Singapore', 'Singapore', '']\n",
      "['10', 'UCLA Health - Ronald Reagan Medical Center', 'United States', 'Los Angeles', 'CA']\n",
      "['11', 'Sheba Medical Center', 'Israel', 'Ramat Gan', '']\n",
      "['12', 'Universit?tsspital Z?rich', 'Switzerland', 'Z?rich', '']\n",
      "['13', 'Universit?tsklinikum Heidelberg', 'Germany', 'Heidelberg', '']\n",
      "['14', 'Centre Hospitalier Universitaire Vaudois', 'Switzerland', 'Lausanne', '']\n",
      "['15', 'Universit?tsspital Basel', 'Switzerland', 'Basel', '']\n",
      "['16', 'Stanford Health Care - Stanford Hospital', 'United States', 'Stanford', 'CA']\n",
      "['17', 'The University of Tokyo Hospital', 'Japan', 'Tokyo', '']\n",
      "['18', \"Brigham And Women's Hospital\", 'United States', 'Boston', 'MA']\n",
      "['19', 'AP-HP - H?pital Europ?en Georges Pompidou', 'France', 'Paris', '']\n",
      "['20', 'Klinikum rechts der Isar der Technischen Universit?t M?nchen', 'Germany', 'M?nchen', '']\n",
      "['21', 'Northwestern Memorial Hospital', 'United States', 'Chicago', 'IL']\n",
      "['22', 'Sunnybrook Health Sciences Centre', 'Canada', 'Toronto', '']\n",
      "['23', 'The Mount Sinai Hospital', 'United States', 'New York', 'NY']\n",
      "['24', 'Aarhus Universitetshospital', 'Denmark', 'Aarhus', '']\n",
      "['25', 'New York-Presbyterian Hospital-Columbia and Cornell', 'United States', 'New York', 'NY']\n",
      "['26', 'Mount Sinai Hospital', 'Canada', 'Toronto', '']\n",
      "['27', 'Rigshospitalet - K?benhavn', 'Denmark', 'K?benhavn', '']\n",
      "['28', \"St. Luke's International Hospital\", 'Japan', 'Tokyo', '']\n",
      "['29', 'Asan Medical Center', 'South Korea', 'Seoul', '']\n",
      "['30', 'Allgemeines Krankenhaus der Stadt Wien - Medizinischer Universit?tscampus', 'Austria', 'Wien', '']\n",
      "['31', 'LMU Klinikum', 'Germany', 'M?nchen', '']\n",
      "['32', 'Medizinische Hochschule Hannover', 'Germany', 'Hannover', '']\n",
      "['33', 'University of Michigan Hospitals - Michigan Medicine', 'United States', 'Ann Arbor', 'MI']\n",
      "['34', 'Hospital Israelita Albert Einstein', 'Brazil', 'Sao Paulo', '']\n",
      "['35', 'Cedars-Sinai Medical Center', 'United States', 'Los Angeles', 'CA']\n",
      "['36', 'Amsterdam UMC', 'The Netherlands', 'Amsterdam', '']\n",
      "['37', 'Oslo Universitetssykehus', 'Norway', 'Oslo', '']\n",
      "['38', 'Policlinico Universitario A. Gemelli', 'Italy', 'Roma', '']\n",
      "['39', 'Helsinki University Hospital', 'Finland', 'Helsinki', '']\n",
      "['40', 'Samsung Medical Center', 'South Korea', 'Seoul', '']\n",
      "['41', 'CHU Lille - H?pital Claude-Huriez', 'France', 'Lille', '']\n",
      "['42', \"St Thomas' Hospital\", 'United Kingdom', 'London', '']\n",
      "['43', 'Universit?tsklinikum Hamburg-Eppendorf', 'Germany', 'Hamburg', '']\n",
      "['44', 'UCSF Medical Center', 'United States', 'San Francisco', 'CA']\n",
      "['45', 'Duke University Hospital', 'United States', 'Durham', 'NC']\n",
      "['46', 'UMC Utrecht', 'The Netherlands', 'Utrecht', '']\n",
      "['47', 'Kameda Medical Center', 'Japan', 'Kamogawa', '']\n",
      "['48', 'UZ Leuven', 'Belgium', 'Leuven/Pellenberg', '']\n",
      "['49', 'Seoul National University Hospital', 'South Korea', 'Seoul', '']\n",
      "['50', 'Hospital of the University of Pennsylvania - Penn Presbyterian', 'United States', 'Philadelphia', 'PA']\n"
     ]
    }
   ],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# 1. launch browser (change to the path to your driver)\n",
    "browser = Browser('firefox', headless=True)  # or 'chrome'\n",
    "\n",
    "url = \"https://rankings.newsweek.com/worlds-best-hospitals-2023\"\n",
    "browser.visit(url)\n",
    "time.sleep(5)  # wait initial load\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "while True:\n",
    "    # parse current page\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    table = soup.find(\"table\")  # or locate by CSS class/id if available\n",
    "    if not table:\n",
    "        print(\"Table not found\")\n",
    "        break\n",
    "    rows = table.select(\"tr\")[1:]  # skip header\n",
    "    for tr in rows:\n",
    "        cols = tr.find_all([\"td\",\"th\"])\n",
    "        values = [c.get_text(strip=True) for c in cols]\n",
    "        all_rows.append(values)\n",
    "\n",
    "    # find “Load more” or “Next page” button\n",
    "    # adjust selector based on actual button attributes\n",
    "    btn = browser.find_by_text(\"Load more\") or browser.find_by_text(\"Next\")\n",
    "    if btn and btn.visible:\n",
    "        btn.first.click()\n",
    "        time.sleep(3)  # wait for new rows to load\n",
    "    else:\n",
    "        break\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "# Now all_rows holds scraped rows\n",
    "for r in all_rows:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ba6dda-c164-4015-9f45-0e9c56af7698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "  Rank                             Publication name        Country       City  \\\n",
      "0    1                      Mayo Clinic - Rochester  United States  Rochester   \n",
      "1    2                             Cleveland Clinic  United States  Cleveland   \n",
      "2    3               Massachusetts General Hospital  United States     Boston   \n",
      "3    4                   The Johns Hopkins Hospital  United States  Baltimore   \n",
      "4    5  Toronto General - University Health Network         Canada    Toronto   \n",
      "\n",
      "  State (US only)  \n",
      "0              MN  \n",
      "1              OH  \n",
      "2              MA  \n",
      "3              MD  \n",
      "4                  \n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Setup using Service (compatible with new Selenium versions)\n",
    "service = Service(executable_path=ChromeDriverManager().install())\n",
    "browser = Browser('chrome', service=service, headless=False)\n",
    "\n",
    "url = \"https://rankings.newsweek.com/worlds-best-hospitals-2023\"\n",
    "browser.visit(url)\n",
    "time.sleep(5)\n",
    "\n",
    "all_data = []\n",
    "headers = []\n",
    "\n",
    "for i in range(5):  # Adjust number of pages\n",
    "    print(f\"Scraping page {i+1}...\")\n",
    "\n",
    "    # Parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(browser.html, \"html.parser\")\n",
    "    table = soup.find(\"table\")\n",
    "\n",
    "    if i == 0:\n",
    "        headers = [th.get_text(strip=True) for th in table.find(\"thead\").find_all(\"th\")]\n",
    "\n",
    "    rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        cells = [cell.get_text(strip=True) for cell in row.find_all(\"td\")]\n",
    "        all_data.append(cells)\n",
    "\n",
    "    # Click next page\n",
    "    next_button = browser.find_by_css('button[aria-label=\"Go to next page\"]')\n",
    "    if next_button and next_button.visible:\n",
    "        next_button.click()\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "# Show first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45d9346-955e-4808-b817-4770fc7cce0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2529f6e7-4aa1-4bda-86aa-4eca1b3ce7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "  Rank                             Publication name        Country       City  \\\n",
      "0    1                      Mayo Clinic - Rochester  United States  Rochester   \n",
      "1    2                             Cleveland Clinic  United States  Cleveland   \n",
      "2    3               Massachusetts General Hospital  United States     Boston   \n",
      "3    4                   The Johns Hopkins Hospital  United States  Baltimore   \n",
      "4    5  Toronto General - University Health Network         Canada    Toronto   \n",
      "\n",
      "  State (US only)  \n",
      "0              MN  \n",
      "1              OH  \n",
      "2              MA  \n",
      "3              MD  \n",
      "4                  \n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up browser (Chrome with webdriver-manager)\n",
    "service = Service(executable_path=ChromeDriverManager().install())\n",
    "browser = Browser('chrome', service=service, headless=False)\n",
    "\n",
    "# Visit Newsweek's hospital rankings page\n",
    "url = \"https://rankings.newsweek.com/worlds-best-hospitals-2023\"\n",
    "browser.visit(url)\n",
    "time.sleep(5)  # allow JavaScript to render\n",
    "\n",
    "all_data = []\n",
    "headers = []\n",
    "\n",
    "# Loop through the first 5 pages\n",
    "for i in range(5):\n",
    "    print(f\"Scraping page {i + 1}...\")\n",
    "\n",
    "    # Parse page content\n",
    "    soup = BeautifulSoup(browser.html, \"html.parser\")\n",
    "    table = soup.find(\"table\")\n",
    "\n",
    "    # Grab headers only on first page\n",
    "    if i == 0:\n",
    "        headers = [th.get_text(strip=True) for th in table.find(\"thead\").find_all(\"th\")]\n",
    "\n",
    "    # Grab rows\n",
    "    rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        cells = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "        all_data.append(cells)\n",
    "\n",
    "    # Click \"Next page\" button using correct selector\n",
    "    next_button = browser.find_by_css('button[aria-label=\"Next page\"]')\n",
    "    if next_button and next_button.visible:\n",
    "        next_button.click()\n",
    "        time.sleep(3)  # wait for new page to load\n",
    "    else:\n",
    "        print(\"Next button not found or no longer available.\")\n",
    "        break\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "# Display preview\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ed9448-d8c5-4688-be07-2b1353f7d511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication name</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>State (US only)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mayo Clinic - Rochester</td>\n",
       "      <td>United States</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cleveland Clinic</td>\n",
       "      <td>United States</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Massachusetts General Hospital</td>\n",
       "      <td>United States</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Johns Hopkins Hospital</td>\n",
       "      <td>United States</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Toronto General - University Health Network</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Toronto</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>246</td>\n",
       "      <td>Yokohama Municipal Citizen's Hospital</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Yokohama</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>247</td>\n",
       "      <td>Chungnam National University Hospital</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>Daejeon</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>Centro M?dico ABC Campus Santa Fe</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Ciudad de M?xico</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249</td>\n",
       "      <td>National Taiwan University Hospital</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>Taipei City</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>250</td>\n",
       "      <td>Apollo Hospital - Chennai</td>\n",
       "      <td>India</td>\n",
       "      <td>Chennai</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                             Publication name        Country  \\\n",
       "0      1                      Mayo Clinic - Rochester  United States   \n",
       "1      2                             Cleveland Clinic  United States   \n",
       "2      3               Massachusetts General Hospital  United States   \n",
       "3      4                   The Johns Hopkins Hospital  United States   \n",
       "4      5  Toronto General - University Health Network         Canada   \n",
       "..   ...                                          ...            ...   \n",
       "245  246        Yokohama Municipal Citizen's Hospital          Japan   \n",
       "246  247        Chungnam National University Hospital    South Korea   \n",
       "247  248            Centro M?dico ABC Campus Santa Fe         Mexico   \n",
       "248  249          National Taiwan University Hospital         Taiwan   \n",
       "249  250                    Apollo Hospital - Chennai          India   \n",
       "\n",
       "                 City State (US only)  \n",
       "0           Rochester              MN  \n",
       "1           Cleveland              OH  \n",
       "2              Boston              MA  \n",
       "3           Baltimore              MD  \n",
       "4             Toronto                  \n",
       "..                ...             ...  \n",
       "245          Yokohama                  \n",
       "246           Daejeon                  \n",
       "247  Ciudad de M?xico                  \n",
       "248       Taipei City                  \n",
       "249           Chennai                  \n",
       "\n",
       "[250 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
